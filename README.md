# Bangla RAG System - Complete Setup Guide

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.10%2B-blue" alt="Python">
  <img src="https://img.shields.io/badge/Framework-FastAPI-green" alt="Framework">
  <img src="https://img.shields.io/badge/Framework-Langchain-yellow" alt="Langchain">
  <img src="https://img.shields.io/badge/Framework-ChromaDB-blue" alt="ChromaDB">


  
  
</div>

## üîß Features
- Bangla PDF text extraction and processing
- Context-aware question answering with RAG using Langchain Buffer Memory
- FastAPI backend
- Integrations: Cohere reranker, HuggingFace embedding, Groq LLM
- Langchain ChromaDB to store embeddings

---

## üíª System Requirements
- OS: Windows/macOS/Linux
- Python 3.10+
- Tesseract with Bangla Support and Poppler

## üì¶ Setup and Installation Steps

### 1Ô∏è‚É£ Install System Dependencies

#### ü™ü Windows 
#### install python --version=3.10 following documentation
#### Install tesseract wth bangla support
- Tesseract OCR tool with Bangla language support  
  #### üëâ [Download Tesseract](tesseract-ocr-w64-setup-5.5.0.20241111.exe)  for 64 bit windows system or find appropriate version here (https://digi.bib.uni-mannheim.de/tesseract)
  #### After installing, For Bangla language capabiliteis  make sure to select bengali language in language script and language data option during installation. Select Bengali 
  <img width="300" height="100" alt="image" src="https://github.com/user-attachments/assets/a415ddeb-be7f-481e-965c-4108abb51e94" />
  <img width="300" height="60" alt="image" src="https://github.com/user-attachments/assets/3780c01e-4a50-41b3-9f20-6295dac6a252" />
 
---

### After that run in Command Prompt with Admin Privillege 
```bash
bangla-pdf-ocr-setup

```
Verify with this command
```bash
bangla-pdf-ocr-verify

```



#### üçé macOS (using Homebrew)
```bash
brew install python@3.10
brew install tesseract tesseract-lang
brew install poppler
```

#### üêß Linux (Ubuntu/Debian)
```bash
sudo apt update
sudo apt install python3.10 python3.10-venv
sudo apt install tesseract-ocr tesseract-ocr-ben
sudo apt install poppler-utils
```

---

### 2Ô∏è‚É£ Set Up Python Environment

```bash
# Clone the repository
git clone https://github.com/shafaqarefin/RagSystemForBanglaPDF.git
cd RagSystemForBanglaPDF

# Create and activate virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (macOS/Linux)
source venv/bin/activate
```

### Upgrade pip and install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

### üîë API Key Configuration

rename  `.env.example` file in the root directory to .env and add the following keys:



You can get free  keys  after creating account there by simply logging in using google/github or signing up:

- üîó [Cohere API Key](https://dashboard.cohere.com/api-keys)
- üîó [Groq API Key](https://console.groq.com/keys)
- üîó [Hugging Face API Token](https://huggingface.co/settings/tokens) (Use Free tier API Key provided)

### Paste the keys in the apprpriate variables below.Copy and paste these into your .env file

  ```env
COHERE_API_KEY=your_cohere_key_here 
GROQ_API_KEY=your_groq_key_here
HUGGINGFACEHUB_API_TOKEN=your_hf_token_here
```


---

### üöÄ Run the project from CLI Tool
```bash
python cli.py
```

# Sample Input and Output

### Sample Input: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?
### Sample Answer: ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶ï‡ßá

### Sample Input: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?
### Sample Answer: ‡¶ò ‡¶∂‡¶¨‡ßç‡¶¶‡ßÅ‡¶®‡¶æ‡¶• 



# üìò API Documentation - Bangla RAG System
### üñ•Ô∏è Run FastAPI Server
```bash
uvicorn main:app --reload
```

### üîó Base URL
http://localhost:8000

### üì§ `GET /ask`

### ‚û§ Description
This endpoint accepts a query string and returns the answer generated by the RAG pipeline.

### üß† Purpose
Allows users to ask a natural language question (in English or Bangla), which is processed and answered using embedded document chunks and a language model.

---

### üì• Request

**Method:** `GET`  
**Endpoint:** `/ask`  
**Query Parameter:**
- `query` (string, required) ‚Äì The question you want to ask

#‚úÖ Example Request
```bash
curl -X GET "http://localhost:8000/ask?query=‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?
```
---

## üßØ Troubleshooting

### ‚ùå OCR Issues
```bash
tesseract --list-langs
```
Ensure `ben` (Bangla) is listed.

### ‚ùå Python Errors
```bash
pip install --force-reinstall -r requirements.txt
```

### ‚ùå API Connection Problems
- Make sure API keys are valid and not expired
- Check firewall or network restrictions
- Confirm external API services are up

# Question and Answer
## What method or library did you use to extract the text, and why? Did you face any formatting challenges with the PDF content?
Ans: I used the bangla-pdf-ocr library as traditional pdf extraction tools lack bangla encoding and text were garbled.Despite significantly improved text quality,there were still issues like not being able to extract correct spelling,spacing issues,line breaks etc.

## What chunking strategy did you choose (e.g. paragraph-based, sentence-based, character limit)? Why do you think it works well for semantic retrieval?
Ans:I used RecursiveTextSplitter of Langchain due to its ability to detects heading or subsections also added seperators for both english and bangla which give uniformly embedded chunks.


## What embedding model did you use? Why did you choose it? How does it capture the meaning of the text?
Ans: I used model  "intfloat/multilingual-e5-large".It was trained over 100 languages including bengali together which enables it to map different languages similar word togehter like the word cat and ‡¶¨‡¶ø‡ßú‡¶æ‡¶≤ will have similar embeddings.Also it uses transformer based architecture to understand the context to determine embeddings also.Moreover it has a high score in HuggingFace Embedding model rank for mutli language support.

## How are you comparing the query with your stored chunks? Why did you choose this similarity method and storage setup?
Ans: I used vector similarity intially which is a built in function of langchain chroma which uses cosine similarity internally to determine the top similar 10 chunks.This is one of the ways to extract large amount of more or less relevant chunks.

## How do you ensure that the question and the document chunks are compared meaningfully? What would happen if the query is vague or missing context?
Ans: I further used a rerank model as cosine similarity can get irrelevant chunk.Using Coheres reranking  model="rerank-multilingual-v3.5" which is  optimsied for 100+ languages,assign relevance score to the top 10 received chunk initially based on context rather than instead of just vector distance.This increases getting the related chunks.


## Do the results seem relevant? If not, what might improve them (e.g. better chunking, better embedding model, larger document)?
Ans: Yes results seem overall relevant but there is some inconsistency like for example the question  ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤? answer actually lies in the mcq answer index but due to limited chunk size as free tier LLMs wont accept over a certain amount token,this mcq answers index was missed out from the chunk so the LLM had to guess from the question and story passage context which didnot explicitly mention the age.Moreover embeddings dont always capture meaning fully so sometimes irrelevant chunks are received so a better embedding model that can capture context and meaning fully would improve the results more.Lastly better prompts would definitely improve results as even though chat history was provided llm struggled to understand when to reply from context only and when to refer to chat history.











## üë®‚Äçüíª Author
Made by [Shafaq Arefin Chowdhury](https://github.com/shafaqarefin)
